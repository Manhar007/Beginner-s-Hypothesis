{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10393902,"sourceType":"datasetVersion","datasetId":6439745},{"sourceId":10395048,"sourceType":"datasetVersion","datasetId":6440610}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Sample Submission\n\n#### Please note, this notebook is a sample notebook which uses only basic linear regression to make the predictions and submit the csv file, for those who are facing diffuculties in making submissions, and understanding the data.\n\n#### While coding, please ensure you also do your work properly with explanation, as after the end of the competition, a google form will be circulated, wherein you'd be required to submit .ipynb files, with proper explanation and your understanding of the data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load the training data (You might have to change the file path based on how you're working)\ntrain_df = pd.read_csv('/kaggle/input/beginners-hypothesis-25/data_train/working/train.csv')\n\nprint(train_df.head())\n\n# For this notebook, we'll only train for 1000 video samples\n\ntrain_df = train_df[:1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:50:33.296678Z","iopub.execute_input":"2025-01-10T09:50:33.296879Z","iopub.status.idle":"2025-01-10T09:50:33.729763Z","shell.execute_reply.started":"2025-01-10T09:50:33.296859Z","shell.execute_reply":"2025-01-10T09:50:33.728863Z"}},"outputs":[{"name":"stdout","text":"   video_id element  motion power  speed          video_summary\n0         1    Erde  linear   rot    9.6     (3.8147, 31.94809)\n1         2   Feuer     shm  grin    9.6   (26.70288, -4.29153)\n2         3   Feuer  random  geld    9.6      (3.8147, 8.58307)\n3         4    Erde  zigzag  lila    6.9  (-24.79553, -0.95367)\n4         5    Erde  linear  lila    9.6    (7.62939, 22.88818)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cv2 \n\ndef process_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, (64, 64))\n        frames.append(frame)\n    cap.release()\n    frames = np.array(frames)  # Shape: (20, 64, 64, 3)\n    return frames.flatten()  # Flatten to 1D array\n    \nvideo_features = []\nfor idx, row in train_df.iterrows():\n    video_path = f\"/kaggle/input/beginners-hypothesis-25/data_train/working/{row['video_id']}.mp4\"\n    video_features.append(process_video(video_path))\n\nvideo_features = np.array(video_features)  # Shape: (num_samples, 20*64*64*3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:50:33.731305Z","iopub.execute_input":"2025-01-10T09:50:33.731624Z","iopub.status.idle":"2025-01-10T09:50:45.190621Z","shell.execute_reply.started":"2025-01-10T09:50:33.731593Z","shell.execute_reply":"2025-01-10T09:50:45.189878Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"These video features has all the frames of the video stored as a 1D array","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Encode categorical attributes using the Label Encoder\ndef encode_categorical_columns(df, columns):\n    label_encoders = {}\n    for col in columns:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n        label_encoders[col] = le\n    return df, label_encoders\n\ncategorical_columns = ['element', 'motion', 'power']\ntrain_df, label_encoders = encode_categorical_columns(train_df, categorical_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:50:45.192168Z","iopub.execute_input":"2025-01-10T09:50:45.192453Z","iopub.status.idle":"2025-01-10T09:50:45.578372Z","shell.execute_reply.started":"2025-01-10T09:50:45.192432Z","shell.execute_reply":"2025-01-10T09:50:45.577464Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\ny_speed = train_df[['speed']]\ny_summary = train_df['video_summary'].apply(lambda x: eval(x))  # Convert string tuples to actual tuples\n\ny_categorical = train_df[categorical_columns]\n\n# Split data for training and validation\nX_train_speed, X_val_speed, y_train_speed, y_val_speed = train_test_split(video_features, y_speed, test_size=0.2, random_state=42)\nX_train_cat, X_val_cat, y_train_cat, y_val_cat = train_test_split(video_features, y_categorical, test_size=0.2, random_state=42)\nX_train_summary, X_val_summary, y_train_summary, y_val_summary = train_test_split(video_features, y_summary, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:50:45.579675Z","iopub.execute_input":"2025-01-10T09:50:45.580102Z","iopub.status.idle":"2025-01-10T09:50:45.942810Z","shell.execute_reply.started":"2025-01-10T09:50:45.580049Z","shell.execute_reply":"2025-01-10T09:50:45.942144Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n\n# Training linear regression models\nmodel_continuous = LinearRegression()\nmodel_continuous.fit(X_train_speed, y_train_speed)\n\n# Train separate models for categorical attributes\nmodels_categorical = {}\nfor col in categorical_columns:\n    model = LinearRegression()\n    model.fit(X_train_cat, y_train_cat[col])\n    models_categorical[col] = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:50:45.943541Z","iopub.execute_input":"2025-01-10T09:50:45.943763Z","iopub.status.idle":"2025-01-10T09:54:21.800595Z","shell.execute_reply.started":"2025-01-10T09:50:45.943744Z","shell.execute_reply":"2025-01-10T09:54:21.799647Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Training for video_summary, separate models for x and y here\n\nx_values, y_values = zip(*y_train_summary)\n\nmodel_summary_x = LinearRegression()\nmodel_summary_x.fit(X_train_summary, x_values)\n\nmodel_summary_y = LinearRegression()\nmodel_summary_y.fit(X_train_summary, y_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:54:21.801603Z","iopub.execute_input":"2025-01-10T09:54:21.801906Z","iopub.status.idle":"2025-01-10T09:56:08.905968Z","shell.execute_reply.started":"2025-01-10T09:54:21.801881Z","shell.execute_reply":"2025-01-10T09:56:08.905094Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LinearRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Now that the models are trained, we iterate through the test videos, make the predictions and form the submission.csv","metadata":{}},{"cell_type":"code","source":"import os\n\ntest_folder = '/kaggle/input/beginners-hypothesis-25/data_test/test/'\n\ntest_features = []\nvideo_ids = []\n\n# The below function finds all the video ids in the test folder and sorts them, \n# and then stores their features in test_features\n\nfor video_id in sorted(\n    [f for f in os.listdir(test_folder) if f.endswith(\".mp4\")], key=lambda x: int(x.split('.')[0])):\n    video_path = os.path.join(test_folder, video_id)\n    video_ids.append(video_id.split('.')[0]) \n    test_features.append(process_video(video_path))\n\ntest_features = np.array(test_features)  # Shape: (num_test_samples, 20*64*64*3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:08.906810Z","iopub.execute_input":"2025-01-10T09:56:08.907047Z","iopub.status.idle":"2025-01-10T09:56:37.187172Z","shell.execute_reply.started":"2025-01-10T09:56:08.907026Z","shell.execute_reply":"2025-01-10T09:56:37.186378Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"y_test_speed = model_continuous.predict(test_features)\ny_test_summary_x = model_summary_x.predict(test_features)\ny_test_summary_y = model_summary_y.predict(test_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:37.187963Z","iopub.execute_input":"2025-01-10T09:56:37.188208Z","iopub.status.idle":"2025-01-10T09:56:43.323379Z","shell.execute_reply.started":"2025-01-10T09:56:37.188186Z","shell.execute_reply":"2025-01-10T09:56:43.322192Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"y_categorical = {}\n\nfor col in categorical_columns:\n    y_categorical[col] = models_categorical[col].predict(test_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:43.326706Z","iopub.execute_input":"2025-01-10T09:56:43.327756Z","iopub.status.idle":"2025-01-10T09:56:49.466583Z","shell.execute_reply.started":"2025-01-10T09:56:43.327711Z","shell.execute_reply":"2025-01-10T09:56:49.465517Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# As we are doing regression in this notebook, we need to label the numbers back to what they represent using\n# inverse label transform, i.e. 1 will get labelled back as circular for example.\n\ndecoded_categorical = {}\nfor col, predictions in y_categorical.items():\n    rounded_predictions = np.rint(predictions).astype(int)\n    valid_classes = range(len(label_encoders[col].classes_))\n    rounded_predictions = np.clip(rounded_predictions, min(valid_classes), max(valid_classes))\n    decoded_categorical[col] = label_encoders[col].inverse_transform(rounded_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:49.468380Z","iopub.execute_input":"2025-01-10T09:56:49.468981Z","iopub.status.idle":"2025-01-10T09:56:49.477150Z","shell.execute_reply.started":"2025-01-10T09:56:49.468941Z","shell.execute_reply":"2025-01-10T09:56:49.476113Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"speed_predictions = y_test_speed.flatten()  # Ensure the shape is (num_samples,)\nsummary_x_predictions = y_test_summary_x.flatten()\nsummary_y_predictions = y_test_summary_y.flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:49.477904Z","iopub.execute_input":"2025-01-10T09:56:49.478268Z","iopub.status.idle":"2025-01-10T09:56:49.486335Z","shell.execute_reply.started":"2025-01-10T09:56:49.478234Z","shell.execute_reply":"2025-01-10T09:56:49.485305Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"output_df = pd.DataFrame({\n    'video_id': video_ids,                      \n    'element': decoded_categorical['element'],  \n    'motion': decoded_categorical['motion'],\n    'power': decoded_categorical['power'],\n    'speed': speed_predictions,               \n    'video_summary': list(zip(summary_x_predictions, summary_y_predictions)) \n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:49.487193Z","iopub.execute_input":"2025-01-10T09:56:49.487661Z","iopub.status.idle":"2025-01-10T09:56:49.505773Z","shell.execute_reply.started":"2025-01-10T09:56:49.487629Z","shell.execute_reply":"2025-01-10T09:56:49.504871Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"output_df.to_csv(\"submission.csv\", index=False)\n\n# This is the final submission file to be submitted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T09:56:49.506590Z","iopub.execute_input":"2025-01-10T09:56:49.506952Z","iopub.status.idle":"2025-01-10T09:56:49.551147Z","shell.execute_reply.started":"2025-01-10T09:56:49.506918Z","shell.execute_reply":"2025-01-10T09:56:49.550192Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"#### For the participants, you need to perform EDA (Exploratory Data Analysis) well, look for patterns in the data, find some ways to remove the noise for better predictions, both in the videos and text.\n\n#### You are advised to understand all the functions used above in detail, as they'll be helpful in coding further.\n\n# All the best","metadata":{}}]}