{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 238.7252, Val Loss: 239.2298\n",
      "Epoch 2/10, Loss: 238.5590, Val Loss: 239.4200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 146\u001b[0m\n\u001b[0;32m    143\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    144\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 146\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    148\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Evaluate on validation data\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#not working\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Custom Dataset to load videos\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_path, labels_csv, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert video_summary to tuple of (x_summary, y_summary)\n",
    "        self.labels['video_summary'] = self.labels['video_summary'].apply(eval) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_id = self.labels.iloc[idx]['video_id']\n",
    "        video_path = os.path.join(self.folder_path, f\"{video_id}.mp4\")  # Ensure the filename matches `video_id`\n",
    "        \n",
    "        # OpenCV to read the video frames\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        # Read 20 frames from the video\n",
    "        for _ in range(20):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            frame = cv2.resize(frame, (64, 64))  # Resize to 64x64\n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        frames = np.stack(frames)  # Stack to get shape (20, 64, 64, 3)\n",
    "        \n",
    "        # Convert frames to the proper format: (3, 20, 64, 64)\n",
    "        frames = np.transpose(frames, (3, 0, 1, 2))  # Convert to (3, 20, 64, 64)\n",
    "        \n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            frames = self.transform(frames)\n",
    "        \n",
    "        # Extract x_summary and y_summary\n",
    "        x_summary, y_summary = self.labels.iloc[idx]['video_summary']\n",
    "        \n",
    "        return frames, torch.tensor([x_summary, y_summary], dtype=torch.float32)\n",
    "# Define transformations (for tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x / 255.0)  # Normalize the frames to [0, 1]\n",
    "])\n",
    "\n",
    "# Load data and split 80% for training and 20% for testing\n",
    "folder_path = 'BH25/Training_Data/Train_Videos'  # Change to your video folder path\n",
    "labels_csv = 'BH25/Training_Data/train.csv'  # Path to your CSV file\n",
    "\n",
    "dataset = VideoDataset(folder_path, labels_csv, transform=transform)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# cnn to extract features\n",
    "class Custom3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Custom3DCNN, self).__init__()\n",
    "        # Define a 3-layered 3D CNN\n",
    "        self.conv1 = nn.Conv3d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)  # Global average pooling\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the 3D CNN\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Check if CUDA (GPU) is available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the appropriate device\n",
    "model = Custom3DCNN(num_classes=2).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for frames, labels in train_loader:\n",
    "        # Move frames and labels to the same device as the model (GPU or CPU)\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "        # Evaluate on validation data\n",
    "    # model.eval()  # Evaluation mode\n",
    "    # val_loss = 0.0\n",
    "    # with torch.no_grad():\n",
    "    #     for frames, labels in test_loader:\n",
    "    #         frames, labels = frames.to(device), labels.to(device)\n",
    "    #         outputs = model(frames)\n",
    "    #         val_loss += loss_fn(outputs, labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet3d_model2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = Custom3DCNN(num_classes=2)\n",
    "model.load_state_dict(torch.load('resnet3d_model2.pth'))\n",
    "model.to(device)  # Move the model to the selected device\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    for frames, labels in test_loader:\n",
    "        frames, labels = frames.to(device), labels.to(device)  # Move data to the selected device\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_loss = mean_absolute_error(all_labels, all_preds)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
