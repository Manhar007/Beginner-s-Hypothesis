{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this i used normal cnns to extract and pred video summary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 238.6948\n",
      "Epoch 2/10, Loss: 238.5713\n",
      "Epoch 3/10, Loss: 238.4915\n",
      "Epoch 4/10, Loss: 238.5207\n",
      "Epoch 5/10, Loss: 238.3798\n",
      "Epoch 6/10, Loss: 238.2071\n",
      "Epoch 7/10, Loss: 238.0210\n",
      "Epoch 8/10, Loss: 237.6506\n",
      "Epoch 9/10, Loss: 237.4782\n",
      "Epoch 10/10, Loss: 237.3383\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Dataset to load videos\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_path, labels_csv, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert video_summary to tuple of (x_summary, y_summary)\n",
    "        self.labels['video_summary'] = self.labels['video_summary'].apply(eval) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_id = self.labels.iloc[idx]['video_id']\n",
    "        video_path = os.path.join(self.folder_path, f\"{video_id}.mp4\")  # Ensure the filename matches video_id\n",
    "        \n",
    "        # OpenCV to read the video frames\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        # Read 20 frames from the video\n",
    "        for _ in range(20):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n",
    "            frame = cv2.resize(frame, (64, 64))  \n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        frames = np.stack(frames)  # Stack to get shape (20, 64, 64, 3)\n",
    "        \n",
    "        # Convert frames to the proper format: (3, 20, 64, 64)\n",
    "        frames = np.transpose(frames, (3, 0, 1, 2))  \n",
    "        \n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            frames = self.transform(frames)\n",
    "        \n",
    "        # Extract x_summary and y_summary\n",
    "        x_summary, y_summary = self.labels.iloc[idx]['video_summary']\n",
    "        \n",
    "        return frames, torch.tensor([x_summary, y_summary], dtype=torch.float32)\n",
    "\n",
    "# Define transformations (for tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x / 255.0)  # Normalize the frames to [0, 1]\n",
    "])\n",
    "\n",
    "# Load data and split 80% for training and 20% for testing\n",
    "folder_path = 'BH25/Training_Data/Train_Videos' \n",
    "labels_csv = 'BH25/Training_Data/train.csv' \n",
    "\n",
    "dataset = VideoDataset(folder_path, labels_csv, transform=transform)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# Limit the train_dataset to the first 1000 videos\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(2000))\n",
    "\n",
    "# custom CNN model with 3 layers\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc = nn.Linear(128 * 8 * 8 * 2, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the device\n",
    "model = CustomCNN(num_classes=2).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for frames, labels in train_loader:\n",
    "        # Move frames and labels to the same device as the model (GPU or CPU)\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'selfcnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_11556\\1755458686.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('selfcnn.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 12.3206\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = CustomCNN(num_classes=2)\n",
    "model.load_state_dict(torch.load('selfcnn.pth'))\n",
    "model.to(device)  \n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    for frames, labels in test_loader:\n",
    "        frames, labels = frames.to(device), labels.to(device)  \n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_loss = mean_absolute_error(all_labels, all_preds)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making the csv file for test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_11556\\401252137.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('selfcnn.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video summaries have been saved to self_test_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = CustomCNN(num_classes=2)\n",
    "model.load_state_dict(torch.load('selfcnn.pth'))\n",
    "model.to(device)  # Move the model to the selected device\n",
    "model.eval()\n",
    "\n",
    "# Define transformation for input video frames\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),  # Resize if needed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Directory containing test videos\n",
    "test_video_dir = 'BH25/Testing_Data'  # The folder where test videos are stored\n",
    "output_csv_path = 'self_test_summary.csv'  # Path to output CSV file\n",
    "\n",
    "# List to hold video_id and video_summary (tuple of x_summary, y_summary)\n",
    "video_data = []\n",
    "\n",
    "# Iterate over all videos in the test folder\n",
    "for video_id in os.listdir(test_video_dir):\n",
    "    if video_id.endswith(\".mp4\"):  # Ensure the file is a video\n",
    "        video_path = os.path.join(test_video_dir, video_id)\n",
    "        \n",
    "        # Open the video file using OpenCV\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        # Read 20 frames (or all available frames if the video has fewer than 20)\n",
    "        for _ in range(20):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # Stop if video ends or fewer frames are available\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            frames.append(transform(frame))  # Apply transform\n",
    "        \n",
    "        # If there are less than 20 frames, pad with zeros (optional, depending on your needs)\n",
    "        if len(frames) < 20:\n",
    "            for _ in range(20 - len(frames)):\n",
    "                frames.append(torch.zeros((3, 64, 64)))  # Add empty frames\n",
    "        \n",
    "        # Stack frames into a tensor of shape (20, 3, 64, 64)\n",
    "        frames_tensor = torch.stack(frames)  # Shape: [20, 3, 64, 64]\n",
    "        \n",
    "        # Permute the dimensions to match the expected input shape for 3D CNNs\n",
    "        # New shape: [3, 20, 64, 64]\n",
    "        frames_tensor = frames_tensor.permute(1, 0, 2, 3)\n",
    "\n",
    "        # Add batch dimension to the tensor (shape becomes [1, 3, 20, 64, 64])\n",
    "        video_tensor = frames_tensor.unsqueeze(0).to(device)  # Shape: [1, 3, 20, 64, 64]\n",
    "        \n",
    "        # Predict using the trained model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(video_tensor)\n",
    "        \n",
    "        # Get x_summary and y_summary values from the model output\n",
    "        x_summary, y_summary = outputs.cpu().numpy().flatten()\n",
    "\n",
    "        # Add video_id and video_summary as a tuple (x_summary, y_summary) to the results list\n",
    "        video_summary = (x_summary, y_summary)\n",
    "        video_data.append([video_id.split('.')[0], video_summary])\n",
    "\n",
    "        # Release the video capture object\n",
    "        cap.release()\n",
    "\n",
    "# Sort the video_data list by video_id\n",
    "video_data.sort(key=lambda x: x[0])  # Sort by video_id\n",
    "# Create a DataFrame to save the results\n",
    "df = pd.DataFrame(video_data, columns=[\"video_id\", \"video_summary\"])\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Video summaries have been saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
