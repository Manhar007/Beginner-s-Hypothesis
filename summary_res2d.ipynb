{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this instead of using 3d cnn on the video i used only 2d cnn on a single frame of the video\n",
    "which lead to similar mae as that of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset to load videos\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_path, labels_csv, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert video_summary to tuple of (x_summary, y_summary)\n",
    "        self.labels['video_summary'] = self.labels['video_summary'].apply(eval)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_id = self.labels.iloc[idx]['video_id']\n",
    "        video_path = os.path.join(self.folder_path, f\"{video_id}.mp4\")\n",
    "        \n",
    "        # OpenCV to read the first frame of the video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        \n",
    "        if not ret:\n",
    "            raise ValueError(f\"Failed to read video: {video_path}\")\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        frame = cv2.resize(frame, (224, 224))  # Resize to 224x224 for ResNet\n",
    "        \n",
    "        if self.transform:\n",
    "            frame = self.transform(frame)\n",
    "\n",
    "        # Extract x_summary and y_summary\n",
    "        x_summary, y_summary = self.labels.iloc[idx]['video_summary']\n",
    "        \n",
    "        return frame, torch.tensor([x_summary, y_summary], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet model\n",
    "class ResNet2D(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet2D, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load data and split 80% for training and 20% for testing\n",
    "folder_path = 'BH25/Training_Data/Train_Videos'  \n",
    "labels_csv = 'BH25/Training_Data/train.csv'  \n",
    "\n",
    "dataset = VideoDataset(folder_path, labels_csv, transform=transform)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 239.1704\n",
      "Epoch 2/10, Loss: 233.8458\n",
      "Epoch 3/10, Loss: 189.9032\n",
      "Epoch 4/10, Loss: 83.4688\n",
      "Epoch 5/10, Loss: 36.6052\n",
      "Epoch 6/10, Loss: 24.9026\n",
      "Epoch 7/10, Loss: 20.4779\n",
      "Epoch 8/10, Loss: 16.9844\n",
      "Epoch 9/10, Loss: 17.5873\n",
      "Epoch 10/10, Loss: 18.9559\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the  device\n",
    "model = ResNet2D(num_classes=2).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for frames, labels in train_loader:\n",
    "        # Move frames and labels to the same device as the model (GPU or CPU)\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet2d.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model is overfitted here as loss is less but on validation set mae is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_26820\\2037828927.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('resnet2d.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 13.3050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = ResNet2D(num_classes=2)\n",
    "model.load_state_dict(torch.load('resnet2d.pth'))\n",
    "model.to(device)  # Move the model to the selected device\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    for frames, labels in test_loader:\n",
    "        frames, labels = frames.to(device), labels.to(device)  # Move data to the selected device\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # Collect predictions and true labels\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_loss = mean_absolute_error(all_labels, all_preds)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
